OLLAMA_URL=http://localhost:11434
EXPERT_MODEL=gemini-2.0-flash
JUDGE_MODEL=gemini-2.0-flash

# Google Gemini API (get from: https://aistudio.google.com/app/apikey)
GOOGLE_API_KEY=<your-apikey>
GEMINI_MODEL=gemini-2.0-flash

# Embedding Model (using Google Gemini embeddings)
# Options: models/text-embedding-004, models/embedding-001, gemini-embedding-001
GOOGLE_API_KEY_EMBED=<your-apikey>
EMBEDDING_MODEL=gemini-embedding-001

PERSIST_DIR=vectordb/chroma_gemini

# RAG Retrieval Toggle (True/False)
USE_RETRIEVER=False

# Force rebuild vector databases even if they exist (True/False)
# Set to True to rebuild databases from scratch
# Set to False to reuse existing databases (default)
FORCE_REBUILD=False

# Vector build performance settings (adjust based on your API tier)
# Paid tier (default): 3,000 RPM / 1,000,000 TPM
# Free tier: 15 RPM / 1,500 TPM
EMBED_BATCH_SIZE=500       # Chunks per batch (500 for paid, 100 for free)
EMBED_BATCH_DELAY=1.0      # Seconds between batches (1.0 for paid, 5.0 for free)
EMBED_RPM=3000             # Requests per minute limit
EMBED_TPM=1000000          # Tokens per minute limit